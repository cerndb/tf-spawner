#!/usr/bin/env python3

#   Copyright 2019 CERN
#
#   Licensed under the Apache License, Version 2.0 (the "License");
#   you may not use this file except in compliance with the License.
#   You may obtain a copy of the License at
#
#       http://www.apache.org/licenses/LICENSE-2.0
#
#   Unless required by applicable law or agreed to in writing, software
#   distributed under the License is distributed on an "AS IS" BASIS,
#   WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#   See the License for the specific language governing permissions and
#   limitations under the License.

import argparse
import json
import os
import sys
import uuid
import yaml
from kubernetes import client, config

parser = argparse.ArgumentParser(
    formatter_class=argparse.ArgumentDefaultsHelpFormatter)

parser.add_argument("training_script_path",
                    help="path to the TensorFlow script to run",
                    nargs="?")
parser.add_argument(
    "-d", "--delete",
    help="delete resources matching RUN_LABEL",
    action="store_true",
)
parser.add_argument("-w", "--workers", help="number of workers",
                    default="2", type=int)
parser.add_argument("-n", "--namespace",
                    help="k8s namespace (if different than the one specified in your kubeconfig)")
parser.add_argument("-p", "--port", help="grpc port", default="1999", type=int)
parser.add_argument("-c", "--command", help="path to script to use as pod command/ entrypoint")
parser.add_argument("--pod-file", help="path to pod yaml file",
                    default="pod.yaml")
parser.add_argument("-t", "--tag", help="tag resources", default="tf-spawner")
parser.add_argument("-r", "--randomize-tag",
                    help="create random tag for resources (this overrides the -t option)",
                    action="store_true")
parser.add_argument("-e", "--env-file",
                    help="path to file containing environment variables to be sourced into every worker")
parser.add_argument(
    "-i",
    "--image",
    help="container image for the pod to use",
    default="tensorflow/tensorflow:2.1.0-py3",
)
args = parser.parse_args()

NUM_NODES = args.workers
GRPC_PORT = args.port
RED_ESCAPE = "\033[91m"
END_ESCAPE = "\033[0m"

config.load_kube_config()
if args.namespace:
    NSPACE = args.namespace
else:
    try:
        NSPACE = config.list_kube_config_contexts()[1]["context"]["namespace"]
    except Exception:
        NSPACE = "default"

v1 = client.CoreV1Api()

names = [f"worker{i}:{GRPC_PORT}" for i in range(NUM_NODES)]


def print_error(args):
    toprint = ' '.join(args) if isinstance(args, list) else args
    print(RED_ESCAPE, toprint, END_ESCAPE, file=sys.stderr)


def gen_tfconfig(names, index):
    # TF_CONFIG={"cluster": {"worker":
    #      ["worker0:1999", "worker1:1999", "worker2:1999"]},
    #    "task": {"type": "worker", "index": 0}}

    tfconfig = {}
    tfconfig["cluster"] = {}
    tfconfig["cluster"]["worker"] = names
    tfconfig["task"] = {"type": "worker", "index": index}
    return json.dumps(tfconfig)


def gen_cfmap(script_path, selector_name):
    with open(script_path) as script_file:
        cm = v1.create_namespaced_config_map(
            NSPACE,
            client.V1ConfigMap(
                data={"training-script.py": script_file.read()},
                metadata=client.V1ObjectMeta(
                    name="script", labels={"training_attempt": selector_name}
                ),
            ),
        )
    return cm


with open("service.yaml") as service_f:
    service_template = yaml.safe_load(service_f)

with open(args.pod_file) as pod_f:
    pod_template = yaml.safe_load(pod_f)


def gen_script(entrypoint_path):
    with open(entrypoint_path) as script_f:
        lines = script_f.read().splitlines()
        lines = [x for x in lines if not x.strip() == '']
        sh_script = ["/bin/bash", "-c", "&& ".join(lines)]
        return sh_script


def gen_services(n_services, selector_name):
    for i in range(n_services):
        service_body = service_template
        service_body["spec"]["selector"]["app"] = f"worker{i}"
        service_body["spec"]["ports"][0]["port"] = GRPC_PORT
        service_body["spec"]["ports"][0]["targetPort"] = GRPC_PORT
        service_body["metadata"]["name"] = f"worker{i}"
        service_body["metadata"]["labels"]["training_attempt"] = selector_name
        v1.create_namespaced_service(NSPACE, service_body)


def add_vars_to_env(env, index, envfile):
    with open(envfile) as f:
        for line in f.readlines():
            var, value = line.strip().split("=", 1)
            env.update({var: value})
    return env


def gen_pods(n_pods, selector_name):
    if args.command:
        command = gen_script(args.command)
    for i in range(n_pods):
        pod_body = pod_template
        pod_body["metadata"]["name"] = f"worker{i}"
        pod_body["metadata"]["labels"]["app"] = f"worker{i}"
        pod_body["metadata"]["labels"]["training_attempt"] = selector_name
        env = {
            "TF_CONFIG": gen_tfconfig(names, i),
            "WORKER_NUMBER": str(i),
            "TOT_WORKERS": str(NUM_NODES),
        }
        if args.env_file:
            env = add_vars_to_env(env, i, args.env_file)
        pod_body["spec"]["containers"][0]["env"] = []
        for k, v in env.items():
            pod_body["spec"]["containers"][0]["env"].append(
                {"name": k, "value": v})
        if args.command:
            pod_body["spec"]["containers"][0]["command"] = command
        pod_body["spec"]["containers"][0]["image"] = args.image
        v1.create_namespaced_pod(NSPACE, pod_body)


if args.delete:
    print(f"This will delete the resources tagged with: {args.tag}. Confirm with y/[n]")
    confirmation = input()
    if confirmation == 'y':
        services = v1.list_namespaced_service(
            NSPACE, label_selector=f"training_attempt={args.tag}"
            )
        for svc in services.items:
            print(f"removing '{svc.metadata.name}' service")
            v1.delete_namespaced_service(svc.metadata.name, NSPACE)
        cms = v1.list_namespaced_config_map(
            NSPACE, label_selector=f"training_attempt={args.tag}"
            )
        for cm in cms.items:
            print(f"removing '{cm.metadata.name}' config map")
            v1.delete_namespaced_config_map(cm.metadata.name, NSPACE)
        pods = v1.list_namespaced_pod(
            NSPACE, label_selector=f"training_attempt={args.tag}"
            )
        for pod in pods.items:
            print(f"removing '{pod.metadata.name}' pod")
            v1.delete_namespaced_pod(pod.metadata.name, NSPACE)
else:
    if not args.training_script_path:
        raise Exception("no script specified")
    if args.randomize_tag:
        selector_name = str(uuid.uuid4())[:8]
    else:
        selector_name = args.tag
    existing_conf = v1.list_namespaced_config_map(
            NSPACE, label_selector=f"training_attempt={selector_name}"
        )
    if len(existing_conf.items) > 0:
        print_error([f"error: a job with label {selector_name} exists already",
                     f"to remove this error, either use a different tag (-t)",
                     f"or use a random one with -r",
                     f"you can delete the job that is running with:"])
        print(f"./tf-spawner -d -t {selector_name}")
        # if this sys.exit is removed, the script will go on and remove
        # silently a job
        sys.exit()
    try:
        gen_cfmap(args.training_script_path, selector_name)
        gen_pods(NUM_NODES, selector_name)
        gen_services(NUM_NODES, selector_name)
        print(f"generated with label training_attempt={selector_name}")
    except client.rest.ApiException as e:
        print_error(["deployment failed, cleaning_up \n", e.body])
        half_created_cms = v1.list_namespaced_config_map(
            NSPACE, label_selector=f"training_attempt={selector_name}"
        )
        for cm in half_created_cms.items:
            print(f"removing '{cm.metadata.name}' config map")
            v1.delete_namespaced_config_map(cm.metadata.name, NSPACE)
        half_created_pods = v1.list_namespaced_pod(
            NSPACE, label_selector=f"training_attempt={selector_name}"
        )
        for pod in half_created_pods.items:
            print(f"removing '{pod.metadata.name}' pod")
            v1.delete_namespaced_pod(pod.metadata.name, NSPACE)
        half_created_svcs = v1.list_namespaced_service(
            NSPACE, label_selector=f"training_attempt={selector_name}"
        )
        for svc in half_created_svcs.items:
            print(f"removing '{svc.metadata.name}' service")
            v1.delete_namespaced_service(svc.metadata.name, NSPACE)
